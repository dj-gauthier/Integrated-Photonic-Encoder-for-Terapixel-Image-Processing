{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive Ratio 8:1 Neural Network Training\n",
    "\n",
    "This notebook demonstrates the construction and training of a neural network optimized for a compressive ratio of 8:1. The network takes 64 inputs and produces 8 outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchinfo import summary\n",
    "from NN_module import Upsample, Residual\n",
    "from utils import (SampleDataset, save_checkpoint, load_checkpoint,\n",
    "                   get_loaders, check_accuracy, save_predicitons_as_imgs, init_weights)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channel, filters=[64, 128, 256, 512]):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Conv2d(channel, filters[0],\n",
    "                      kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(filters[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filters[0], filters[0],\n",
    "                      kernel_size=3, padding=1, bias=False),\n",
    "        )\n",
    "        self.input_skip = nn.Sequential(\n",
    "            nn.Conv2d(channel, filters[0],\n",
    "                      kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.residual_conv_1 = Residual(\n",
    "            filters[0], filters[1], use_1x1conv=True)\n",
    "        self.downsample_1 = nn.Sequential(\n",
    "            nn.Conv2d(filters[1], filters[1], kernel_size=3,\n",
    "                      padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(filters[1]),\n",
    "        )\n",
    "\n",
    "        self.residual_conv_2 = Residual(\n",
    "            filters[1], filters[2], use_1x1conv=True)\n",
    "        self.downsample_2 = nn.Sequential(\n",
    "            nn.Conv2d(filters[2], filters[2], kernel_size=3,\n",
    "                      padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(filters[2]),\n",
    "        )\n",
    "\n",
    "        self.bridge = Residual(filters[2], filters[3], use_1x1conv=True)\n",
    "\n",
    "        self.upsample_1 = Upsample(filters[3], filters[3], 2, 2)\n",
    "        self.up_residual_conv1 = Residual(\n",
    "            filters[3] + filters[2], filters[2],\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "\n",
    "        self.upsample_2 = Upsample(filters[2], filters[2], 2, 2)\n",
    "        self.up_residual_conv2 = Residual(\n",
    "            filters[2] + filters[1], filters[1],\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "\n",
    "        self.upsample_3 = Upsample(filters[1], filters[1], 2, 2)\n",
    "        self.up_residual_conv3 = Residual(\n",
    "            filters[1], filters[0],\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "\n",
    "        self.upsample_4 = Upsample(filters[0], filters[0], 2, 2)\n",
    "        self.up_residual_conv4 = Residual(\n",
    "            filters[0], filters[0]//2,\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "\n",
    "        self.upsample_5 = Upsample(filters[0]//2, filters[0]//2, 2, 2)\n",
    "        self.up_residual_conv5 = Residual(\n",
    "            filters[0]//2, filters[0]//4,\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "\n",
    "        self.up_residual_conv6 = Residual(\n",
    "            filters[0]//4, filters[0]//8,\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "        self.up_residual_conv7 = Residual(\n",
    "            filters[0]//8, filters[0]//16,\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "        self.up_residual_conv8 = Residual(\n",
    "            filters[0]//16, filters[0]//32,\n",
    "            paddings=1, strides=1, use_1x1conv=True\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Conv2d(filters[0]//32, 1, 1, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        x1 = self.input_layer(x) + self.input_skip(x)  # 64, 64, 64\n",
    "        x1 = self.residual_conv_1(x1)  # 128, 64, 64\n",
    "        x2 = self.downsample_1(x1)  # 128, 32, 32\n",
    "        x2 = self.residual_conv_2(x2)  # 256, 32, 32\n",
    "        x3 = self.downsample_2(x2)  # 256, 16, 16\n",
    "\n",
    "        # Bridge\n",
    "        x4 = self.bridge(x3)  # 512, 16, 16\n",
    "\n",
    "        # Decode\n",
    "        x5 = self.upsample_1(x4)  # 1024, 32, 32\n",
    "        x5 = torch.cat([x5, x2], dim=1)  # 1536, 32, 32\n",
    "        x5 = self.up_residual_conv1(x5)  # 512, 32, 32\n",
    "\n",
    "        x6 = self.upsample_2(x5)  # 512, 64, 64\n",
    "        x6 = torch.cat([x6, x1], dim=1)  # 768, 64, 64\n",
    "        x6 = self.up_residual_conv2(x6)  # 256, 64, 64\n",
    "\n",
    "        x7 = self.upsample_3(x6)  # 256, 128, 128\n",
    "        x7 = self.up_residual_conv3(x7)  # 128, 128, 128\n",
    "\n",
    "        x8 = self.upsample_4(x7)  # 128, 256, 256\n",
    "        x8 = self.up_residual_conv4(x8)  # 64, 256, 256\n",
    "\n",
    "        x9 = self.upsample_5(x8)  # 64, 512, 512\n",
    "        x9 = self.up_residual_conv5(x9)  # 32, 512, 512\n",
    "\n",
    "        # residual blocks\n",
    "        x10 = self.up_residual_conv6(x9)  # 16, 512, 512\n",
    "        x11 = self.up_residual_conv7(x10)  # 16, 512, 512\n",
    "        x12 = self.up_residual_conv8(x11)  # 8, 512, 512\n",
    "\n",
    "        output = self.output_layer(x12)  # 1, 512, 512\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = torch.randn((1, 8, 64, 64)).to(device='cpu', dtype=torch.float)\n",
    "    model = Decoder(channel=8)\n",
    "    model = model.to(device='cpu', dtype=torch.float)\n",
    "    preds = model(x)\n",
    "#     torch.save(model, 'test.pt')\n",
    "    print('input:', x.shape)\n",
    "    print('output:', preds.shape)\n",
    "    print()\n",
    "    print(summary(model, input_size=(1, 8, 64, 64), device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 8, 64, 64])\n",
      "output: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Decoder                                  [1, 1, 512, 512]          --\n",
      "├─Sequential: 1-1                        [1, 64, 64, 64]           --\n",
      "│    └─Conv2d: 2-1                       [1, 64, 64, 64]           4,608\n",
      "│    └─BatchNorm2d: 2-2                  [1, 64, 64, 64]           128\n",
      "│    └─LeakyReLU: 2-3                    [1, 64, 64, 64]           --\n",
      "│    └─Conv2d: 2-4                       [1, 64, 64, 64]           36,864\n",
      "├─Sequential: 1-2                        [1, 64, 64, 64]           --\n",
      "│    └─Conv2d: 2-5                       [1, 64, 64, 64]           4,608\n",
      "├─Residual: 1-3                          [1, 128, 64, 64]          --\n",
      "│    └─Conv2d: 2-6                       [1, 128, 64, 64]          73,728\n",
      "│    └─BatchNorm2d: 2-7                  [1, 128, 64, 64]          256\n",
      "│    └─Conv2d: 2-8                       [1, 128, 64, 64]          147,456\n",
      "│    └─BatchNorm2d: 2-9                  [1, 128, 64, 64]          256\n",
      "│    └─Conv2d: 2-10                      [1, 128, 64, 64]          8,192\n",
      "├─Sequential: 1-4                        [1, 128, 32, 32]          --\n",
      "│    └─Conv2d: 2-11                      [1, 128, 32, 32]          147,456\n",
      "│    └─BatchNorm2d: 2-12                 [1, 128, 32, 32]          256\n",
      "├─Residual: 1-5                          [1, 256, 32, 32]          --\n",
      "│    └─Conv2d: 2-13                      [1, 256, 32, 32]          294,912\n",
      "│    └─BatchNorm2d: 2-14                 [1, 256, 32, 32]          512\n",
      "│    └─Conv2d: 2-15                      [1, 256, 32, 32]          589,824\n",
      "│    └─BatchNorm2d: 2-16                 [1, 256, 32, 32]          512\n",
      "│    └─Conv2d: 2-17                      [1, 256, 32, 32]          32,768\n",
      "├─Sequential: 1-6                        [1, 256, 16, 16]          --\n",
      "│    └─Conv2d: 2-18                      [1, 256, 16, 16]          589,824\n",
      "│    └─BatchNorm2d: 2-19                 [1, 256, 16, 16]          512\n",
      "├─Residual: 1-7                          [1, 512, 16, 16]          --\n",
      "│    └─Conv2d: 2-20                      [1, 512, 16, 16]          1,179,648\n",
      "│    └─BatchNorm2d: 2-21                 [1, 512, 16, 16]          1,024\n",
      "│    └─Conv2d: 2-22                      [1, 512, 16, 16]          2,359,296\n",
      "│    └─BatchNorm2d: 2-23                 [1, 512, 16, 16]          1,024\n",
      "│    └─Conv2d: 2-24                      [1, 512, 16, 16]          131,072\n",
      "├─Upsample: 1-8                          [1, 512, 32, 32]          --\n",
      "│    └─ConvTranspose2d: 2-25             [1, 512, 32, 32]          1,048,576\n",
      "├─Residual: 1-9                          [1, 256, 32, 32]          --\n",
      "│    └─Conv2d: 2-26                      [1, 256, 32, 32]          1,769,472\n",
      "│    └─BatchNorm2d: 2-27                 [1, 256, 32, 32]          512\n",
      "│    └─Conv2d: 2-28                      [1, 256, 32, 32]          589,824\n",
      "│    └─BatchNorm2d: 2-29                 [1, 256, 32, 32]          512\n",
      "│    └─Conv2d: 2-30                      [1, 256, 32, 32]          196,608\n",
      "├─Upsample: 1-10                         [1, 256, 64, 64]          --\n",
      "│    └─ConvTranspose2d: 2-31             [1, 256, 64, 64]          262,144\n",
      "├─Residual: 1-11                         [1, 128, 64, 64]          --\n",
      "│    └─Conv2d: 2-32                      [1, 128, 64, 64]          442,368\n",
      "│    └─BatchNorm2d: 2-33                 [1, 128, 64, 64]          256\n",
      "│    └─Conv2d: 2-34                      [1, 128, 64, 64]          147,456\n",
      "│    └─BatchNorm2d: 2-35                 [1, 128, 64, 64]          256\n",
      "│    └─Conv2d: 2-36                      [1, 128, 64, 64]          49,152\n",
      "├─Upsample: 1-12                         [1, 128, 128, 128]        --\n",
      "│    └─ConvTranspose2d: 2-37             [1, 128, 128, 128]        65,536\n",
      "├─Residual: 1-13                         [1, 64, 128, 128]         --\n",
      "│    └─Conv2d: 2-38                      [1, 64, 128, 128]         73,728\n",
      "│    └─BatchNorm2d: 2-39                 [1, 64, 128, 128]         128\n",
      "│    └─Conv2d: 2-40                      [1, 64, 128, 128]         36,864\n",
      "│    └─BatchNorm2d: 2-41                 [1, 64, 128, 128]         128\n",
      "│    └─Conv2d: 2-42                      [1, 64, 128, 128]         8,192\n",
      "├─Upsample: 1-14                         [1, 64, 256, 256]         --\n",
      "│    └─ConvTranspose2d: 2-43             [1, 64, 256, 256]         16,384\n",
      "├─Residual: 1-15                         [1, 32, 256, 256]         --\n",
      "│    └─Conv2d: 2-44                      [1, 32, 256, 256]         18,432\n",
      "│    └─BatchNorm2d: 2-45                 [1, 32, 256, 256]         64\n",
      "│    └─Conv2d: 2-46                      [1, 32, 256, 256]         9,216\n",
      "│    └─BatchNorm2d: 2-47                 [1, 32, 256, 256]         64\n",
      "│    └─Conv2d: 2-48                      [1, 32, 256, 256]         2,048\n",
      "├─Upsample: 1-16                         [1, 32, 512, 512]         --\n",
      "│    └─ConvTranspose2d: 2-49             [1, 32, 512, 512]         4,096\n",
      "├─Residual: 1-17                         [1, 16, 512, 512]         --\n",
      "│    └─Conv2d: 2-50                      [1, 16, 512, 512]         4,608\n",
      "│    └─BatchNorm2d: 2-51                 [1, 16, 512, 512]         32\n",
      "│    └─Conv2d: 2-52                      [1, 16, 512, 512]         2,304\n",
      "│    └─BatchNorm2d: 2-53                 [1, 16, 512, 512]         32\n",
      "│    └─Conv2d: 2-54                      [1, 16, 512, 512]         512\n",
      "├─Residual: 1-18                         [1, 8, 512, 512]          --\n",
      "│    └─Conv2d: 2-55                      [1, 8, 512, 512]          1,152\n",
      "│    └─BatchNorm2d: 2-56                 [1, 8, 512, 512]          16\n",
      "│    └─Conv2d: 2-57                      [1, 8, 512, 512]          576\n",
      "│    └─BatchNorm2d: 2-58                 [1, 8, 512, 512]          16\n",
      "│    └─Conv2d: 2-59                      [1, 8, 512, 512]          128\n",
      "├─Residual: 1-19                         [1, 4, 512, 512]          --\n",
      "│    └─Conv2d: 2-60                      [1, 4, 512, 512]          288\n",
      "│    └─BatchNorm2d: 2-61                 [1, 4, 512, 512]          8\n",
      "│    └─Conv2d: 2-62                      [1, 4, 512, 512]          144\n",
      "│    └─BatchNorm2d: 2-63                 [1, 4, 512, 512]          8\n",
      "│    └─Conv2d: 2-64                      [1, 4, 512, 512]          32\n",
      "├─Residual: 1-20                         [1, 2, 512, 512]          --\n",
      "│    └─Conv2d: 2-65                      [1, 2, 512, 512]          72\n",
      "│    └─BatchNorm2d: 2-66                 [1, 2, 512, 512]          4\n",
      "│    └─Conv2d: 2-67                      [1, 2, 512, 512]          36\n",
      "│    └─BatchNorm2d: 2-68                 [1, 2, 512, 512]          4\n",
      "│    └─Conv2d: 2-69                      [1, 2, 512, 512]          8\n",
      "├─Conv2d: 1-21                           [1, 1, 512, 512]          3\n",
      "==========================================================================================\n",
      "Total params: 10,356,735\n",
      "Trainable params: 10,356,735\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 20.39\n",
      "==========================================================================================\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 652.21\n",
      "Params size (MB): 41.43\n",
      "Estimated Total Size (MB): 693.77\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "## show network architecture\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 800\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "valid_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "## training, validation, and test dataset\n",
    "TRAIN_SAMPLE_DIR = \"path to your training dataset sample directory\"\n",
    "TRAIN_TARGET_DIR = \"path to your training dataset target directory\"\n",
    "VAL_SAMPLE_DIR = \"path to your validation dataset sample directory\"\n",
    "VAL_TARGET_DIR = \"path to your validation dataset sample directory\"\n",
    "TEST_TSAMPLE_DIR = \"path to your test dataset sample directory\"\n",
    "TEST_TARGET_DIR = \"path to your test dataset sample directory\"\n",
    "\n",
    "## folder to save predicted images\n",
    "pred_dirs = 'path to your prediction directory'\n",
    "if not os.path.exists(pred_dirs):\n",
    "    os.makedirs(pred_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE, dtype=torch.float32)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE, dtype=torch.float32)\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            train_loss_list.append(np.mean(loss.cpu().detach().numpy()))\n",
    "            \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "def train_main():\n",
    "    model = Decoder(channel=8).to(device=DEVICE, dtype=torch.float32)\n",
    "    model.apply(init_weights)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=500, gamma=0.1, verbose=True)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        TRAIN_SAMPLE_DIR,\n",
    "        TRAIN_TARGET_DIR,\n",
    "        VAL_SAMPLE_DIR,\n",
    "        VAL_TARGET_DIR,\n",
    "        BATCH_SIZE,\n",
    "        NUM_WORKERS,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        try:\n",
    "            load_checkpoint(torch.load(\n",
    "                'my_checkpoint_Decoder_64in8out_real.pth.tar'), model)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    valid_loss_list.append(check_accuracy(val_loader, model, device=DEVICE))\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print('present learning rate: {0}'.format(\n",
    "            optimizer.param_groups[0]['lr']))\n",
    "        print(f'Epoch #{epoch}')\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "        # save model\n",
    "        checkpoint = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        save_checkpoint(\n",
    "            checkpoint, filename='my_checkpoint_Decoder_64in8out_real.pth.tar')\n",
    "        torch.save(model, 'my_checkpoint_Decoder_64in8out_real.pt')\n",
    "\n",
    "        # check accuracy\n",
    "        valid_loss_list.append(check_accuracy(val_loader, model, device=DEVICE))\n",
    "\n",
    "        # save the best model\n",
    "        if np.min(valid_loss_list) == valid_loss_list[-1]:\n",
    "            torch.save(model, 'my_checkpoint_Decoder_64in8out_real_best.pt')\n",
    "            save_checkpoint(\n",
    "                checkpoint, filename='my_checkpoint_Decoder_64in8out_real_best.pth.tar')\n",
    "\n",
    "        # output examples to a folder\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            save_predicitons_as_imgs(\n",
    "                val_loader, model, folder=pred_dirs, device=DEVICE\n",
    "            )\n",
    "\n",
    "        scheduler.step()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## train the network\n",
    "train_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot MSE loss of training and validation dataset\n",
    "plt.figure(figsize=(21, 9))\n",
    "plt.plot(train_loss_list, '-o', label='train')\n",
    "plt.plot(valid_loss_list, '-o', label='valid')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase_retrieval",
   "language": "python",
   "name": "phase_retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
